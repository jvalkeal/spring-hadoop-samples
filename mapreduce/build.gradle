description = 'Spring Hadoop Examples'
defaultTasks 'build'

apply plugin: 'base'

buildscript {
	repositories {
		maven { url "http://repo.springsource.org/plugins-release" }
	}
	dependencies {
		classpath("org.springframework.build.gradle:docbook-reference-plugin:0.2.6")
	}
}

allprojects {
	group = 'org.springframework.data.hadoop'
	//logging.captureStandardOutput LogLevel.DEBUG
 
	repositories {
		mavenLocal()
		maven { url 'http://repo.springsource.org/libs-milestone' }
		mavenCentral()
	}
}

def hadoopDefault = "hadoop22"
def hadoopDistro = project.hasProperty("distro") ? project.getProperty("distro") : hadoopDefault
def springDataVersion = hadoop22SpringDataVersion

switch (hadoopDistro) {

	// vanilla hadoop 2.2.x
	case "hadoop22":
		springDataVersion = hadoop22SpringDataVersion
		println "Using Apache Hadoop 2.2.x Spring Hadoop Dependencies - [$springDataVersion]"
	break;

	// pivotal
	case "phd1":
		springDataVersion = phd1SpringDataVersion
		println "Using Pivotal HD 1.0 Spring Hadoop Dependencies - [$springDataVersion]"
	break;

	default:
		if (!project.hasProperty("distro")) {
			println "Using default distro: Apache Hadoop Spring Hadoop Dependencies - [$springDataVersion]"
		} else {
			if (hadoopDistro == hadoopDefault) {
				println "Using Apache Hadoop 2.2.x Spring Hadoop Dependencies - [$springDataVersion]"
			} else {
				println "Failing build: $hadoopDistro is not a supported distro"
				println "Supported distros: hadoop22 and phd1"
				println "* default"
				throw new InvalidUserDataException("$hadoopDistro is not a supported distro")
			}
		}
		springDataVersion = hadoop22SpringDataVersion

}

subprojects { subproject ->
	apply plugin: 'idea'
	apply plugin: 'java'
	apply plugin: 'eclipse'
	apply plugin: 'maven'
	
	sourceCompatibility = 1.6
	targetCompatibility = 1.6
	
	eclipse {
		project {
			natures += 'org.springframework.ide.eclipse.core.springnature'
		}
	}

	[compileJava, compileTestJava]*.options*.compilerArgs = ["-Xlint:-serial", "-Xlint:-options"]

	task sourcesJar(type: Jar) {
		classifier = 'sources'
	}

}

def mapreduceExampleProjects() {
	subprojects.findAll { project ->
		project.name.contains('mapreduce-examples-') && project.name != 'mapreduce-examples-common'
	}
}

def mapreduceExampleProjectsWithCommon() {
	subprojects.findAll { project ->
		project.name.contains('mapreduce-examples-')
	}
}

def mapreduceExampleProjectsCommon() {
	subprojects.findAll { project ->
		project.name == 'mapreduce-examples-common'
	}
}

configure(mapreduceExampleProjectsWithCommon()) {
	dependencies {
		compile "org.springframework.data:spring-data-hadoop:$springDataVersion"
		compile "org.springframework.data:spring-data-hadoop-core:$springDataVersion"
		runtime "log4j:log4j:$log4jVersion"
		runtime "org.codehaus.groovy:groovy:$groovyVersion"
		runtime "org.slf4j:slf4j-log4j12:$slf4jVersion"
		runtime "org.apache.hadoop:hadoop-mapreduce-client-jobclient:2.2.0"
		testCompile "org.springframework.data:spring-hadoop-test:$springDataVersion"
		testCompile "org.hamcrest:hamcrest-core:$hamcrestVersion"
		testCompile "org.hamcrest:hamcrest-library:$hamcrestVersion"
	}

	task testJar(type: Jar) {
		classifier = 'tests'
		from sourceSets.test.output
	}

	assemble.dependsOn = ['jar', 'testJar']

	clean.doLast {ant.delete(dir: "target")}

}


configure(mapreduceExampleProjects()) { mapreduceExampleProject ->
	dependencies {
		compile project(":mapreduce-examples-common")
	}
	
	task run(type: JavaExec) {
		description = 'Runs the application'
		classpath = sourceSets.main.runtimeClasspath
		standardInput = System.in
		systemProperties = System.getProperties()
		if (rootProject.hasProperty('args')) {
			args = ["${rootProject.getProperty('args')}"]
		}  
	}

	apply {
		task "run-${mapreduceExampleProject.name}"(dependsOn:'classes') << {
			def mainClass = mapreduceExampleProject.hasProperty('main')? "${mapreduceExampleProject.getProperty('main')}":'CommonMain'
			def args = []
			mapreduceExampleProject.tasks['run'].main = "org.springframework.data.hadoop.examples.$mainClass"
			mapreduceExampleProject.tasks['run'].args = args
			mapreduceExampleProject.tasks['run'].execute()
		}
	}
}

